{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "depression sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr6GSV_CCnES",
        "outputId": "8361d920-7f3c-4645-d758-ed3239d2f4ee"
      },
      "source": [
        "pip install vaderSentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 21.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 23.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6jiTxfofeaC"
      },
      "source": [
        "#Contributors: Michel H. & Kaan A."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m24B4u3Urrj5"
      },
      "source": [
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Rqoad3Cdvc9s",
        "outputId": "0bacdb94-8e32-4a85-84c6-e907ca3004d8"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f16bf9da-32a7-4769-97e0-0d3cd1b75d34\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f16bf9da-32a7-4769-97e0-0d3cd1b75d34\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Womens Clothing E-Commerce Reviews.csv to Womens Clothing E-Commerce Reviews.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP4ZLB6PvqaD",
        "outputId": "51ae190c-c903-4ebe-9db9-b669ebfaaa72"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Womens Clothing E-Commerce Reviews.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "df\n",
        "df[\"Title\"].isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3810"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "pHQv-XKkypU1",
        "outputId": "c9f4f766-ca3a-4752-ae83-aea40fc1d7d4"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23481</th>\n",
              "      <td>23481</td>\n",
              "      <td>1104</td>\n",
              "      <td>34</td>\n",
              "      <td>Great dress for many occasions</td>\n",
              "      <td>I was very happy to snag this dress at such a ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23482</th>\n",
              "      <td>23482</td>\n",
              "      <td>862</td>\n",
              "      <td>48</td>\n",
              "      <td>Wish it was made of cotton</td>\n",
              "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>23483</td>\n",
              "      <td>1104</td>\n",
              "      <td>31</td>\n",
              "      <td>Cute, but see through</td>\n",
              "      <td>This fit well, but the top was very see throug...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23484</th>\n",
              "      <td>23484</td>\n",
              "      <td>1084</td>\n",
              "      <td>28</td>\n",
              "      <td>Very cute dress, perfect for summer parties an...</td>\n",
              "      <td>I bought this dress for a wedding i have this ...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23485</th>\n",
              "      <td>23485</td>\n",
              "      <td>1104</td>\n",
              "      <td>52</td>\n",
              "      <td>Please make more like this one!</td>\n",
              "      <td>This dress in a lovely platinum is feminine an...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23486 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
              "0               0          767   33  ...       Initmates        Intimate   Intimates\n",
              "1               1         1080   34  ...         General         Dresses     Dresses\n",
              "2               2         1077   60  ...         General         Dresses     Dresses\n",
              "3               3         1049   50  ...  General Petite         Bottoms       Pants\n",
              "4               4          847   47  ...         General            Tops     Blouses\n",
              "...           ...          ...  ...  ...             ...             ...         ...\n",
              "23481       23481         1104   34  ...  General Petite         Dresses     Dresses\n",
              "23482       23482          862   48  ...  General Petite            Tops       Knits\n",
              "23483       23483         1104   31  ...  General Petite         Dresses     Dresses\n",
              "23484       23484         1084   28  ...         General         Dresses     Dresses\n",
              "23485       23485         1104   52  ...  General Petite         Dresses     Dresses\n",
              "\n",
              "[23486 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FZchSwuw0Pg",
        "outputId": "f21c940e-c105-4f7a-d1e2-a5d0478c05b9"
      },
      "source": [
        "df=df[['Review Text','Rating']]\n",
        "df.dropna(inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsHujKKbxlse"
      },
      "source": [
        "def encoding(x):\n",
        "  if x in [1,2,3]:\n",
        "    return \"bad\"\n",
        "  else:\n",
        "    return \"good\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woNIdE5WysIm",
        "outputId": "00287dcb-54c7-46d8-f285-f35078c96557"
      },
      "source": [
        "df['value']=df['Rating'].apply(lambda x:encoding(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aTTzFm2A0gCk",
        "outputId": "065ed30b-8e22-4320-f144-18d113fc6218"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23481</th>\n",
              "      <td>I was very happy to snag this dress at such a ...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23482</th>\n",
              "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>This fit well, but the top was very see throug...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23484</th>\n",
              "      <td>I bought this dress for a wedding i have this ...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23485</th>\n",
              "      <td>This dress in a lovely platinum is feminine an...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22641 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Review Text  Rating value\n",
              "0      Absolutely wonderful - silky and sexy and comf...       4  good\n",
              "1      Love this dress!  it's sooo pretty.  i happene...       5  good\n",
              "2      I had such high hopes for this dress and reall...       3   bad\n",
              "3      I love, love, love this jumpsuit. it's fun, fl...       5  good\n",
              "4      This shirt is very flattering to all due to th...       5  good\n",
              "...                                                  ...     ...   ...\n",
              "23481  I was very happy to snag this dress at such a ...       5  good\n",
              "23482  It reminds me of maternity clothes. soft, stre...       3   bad\n",
              "23483  This fit well, but the top was very see throug...       3   bad\n",
              "23484  I bought this dress for a wedding i have this ...       3   bad\n",
              "23485  This dress in a lovely platinum is feminine an...       5  good\n",
              "\n",
              "[22641 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1TT5S1wzYPT",
        "outputId": "e5a35a3a-6687-45c4-f787-50daed44becb"
      },
      "source": [
        "len(df[df[\"Rating\"]==3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-bEQty61Ute",
        "outputId": "f95d9f2e-1647-4d95-c4eb-2270d69b761d"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22641 entries, 0 to 23485\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Review Text  22641 non-null  object\n",
            " 1   Rating       22641 non-null  int64 \n",
            " 2   value        22641 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 707.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydL--4PXSceB",
        "outputId": "6e4e937a-ccc5-4bcd-99de-035cc1a3466b"
      },
      "source": [
        "df[\"value\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "good    17448\n",
              "bad      5193\n",
              "Name: value, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "VldAVnVY8xvq",
        "outputId": "f6cebb2c-ec19-4fec-edb2-ab6342cf1484"
      },
      "source": [
        "# Apply a first round of text cleaning techniques\n",
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text_round1(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "round1 = lambda x: clean_text_round1(x)\n",
        "\n",
        "# Let's take a look at the updated text\n",
        "df['Review Text']=df['Review Text'].apply(round1)\n",
        "\n",
        "\n",
        "# Apply a second round of cleaning\n",
        "def clean_text_round2(text):\n",
        "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    return text\n",
        "\n",
        "round2 = lambda x: clean_text_round2(x)\n",
        "\n",
        "\n",
        "# Let's take a look at the updated text\n",
        "df['Review Text']=df['Review Text'].apply(round2)\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "def clean_text(t):    \n",
        "    tokenized_text = nltk.tokenize.word_tokenize(t.lower())\n",
        "    alphabetic_text = [w for w in tokenized_text if w.isalpha()]\n",
        "    alphabetic_text\n",
        "    t = [w for w in alphabetic_text if w not in stopwords]\n",
        "    stemmed = [stemmer.stem(w) for w in t]\n",
        "    new_text = ' '.join(stemmed)\n",
        "    return new_text\n",
        "round3=lambda x: clean_text(x)\n",
        "\n",
        "df['Review Text']=df['Review Text'].apply(round3)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love dress sooo pretti happen find store im gl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high hope dress realli want work initi order p...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23481</th>\n",
              "      <td>happi snag dress great price easi slip flatter...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23482</th>\n",
              "      <td>remind matern cloth soft stretchi shini materi...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>fit well top see never would work im glad abl ...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23484</th>\n",
              "      <td>bought dress wed summer cute unfortun fit isnt...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23485</th>\n",
              "      <td>dress love platinum feminin fit perfectli easi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22641 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Review Text  Rating value\n",
              "0                      absolut wonder silki sexi comfort       4  good\n",
              "1      love dress sooo pretti happen find store im gl...       5  good\n",
              "2      high hope dress realli want work initi order p...       3   bad\n",
              "3      love love love jumpsuit fun flirti fabul everi...       5  good\n",
              "4      shirt flatter due adjust front tie perfect len...       5  good\n",
              "...                                                  ...     ...   ...\n",
              "23481  happi snag dress great price easi slip flatter...       5  good\n",
              "23482  remind matern cloth soft stretchi shini materi...       3   bad\n",
              "23483  fit well top see never would work im glad abl ...       3   bad\n",
              "23484  bought dress wed summer cute unfortun fit isnt...       3   bad\n",
              "23485  dress love platinum feminin fit perfectli easi...       5  good\n",
              "\n",
              "[22641 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyZ1gBv58xS4",
        "outputId": "790f6f89-f98b-402b-aec8-3c43b39c2618"
      },
      "source": [
        "df['words_count'] = df['Review Text'].map(lambda t: len(t.split(' '))) #split text to make list of words, and len of list is the count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oikPIGSK_buu",
        "outputId": "4fe399b6-8723-44ba-b866-603c4847cf3e"
      },
      "source": [
        "df['punct_count'] = df['Review Text'].map(lambda t: len([x for x in t if x in (';', ':', ',', '.', '!', '?')]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDMn-MN7_lt6",
        "outputId": "1e907e37-b86d-4513-df48-ca05c580af64"
      },
      "source": [
        "df['stopwords_count'] = df['Review Text'].map(lambda t: len([x for x in t if x in stopwords]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_5SXQVb4_pWl",
        "outputId": "fe9e443b-111c-4124-bd8b-d52b7ab5833e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "      <th>words_count</th>\n",
              "      <th>punct_count</th>\n",
              "      <th>stopwords_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love dress sooo pretti happen find store im gl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high hope dress realli want work initi order p...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Text  ...  stopwords_count\n",
              "0                  absolut wonder silki sexi comfort  ...               15\n",
              "1  love dress sooo pretti happen find store im gl...  ...               62\n",
              "2  high hope dress realli want work initi order p...  ...              104\n",
              "3  love love love jumpsuit fun flirti fabul everi...  ...               26\n",
              "4  shirt flatter due adjust front tie perfect len...  ...               31\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCxYwn9MUDBx"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0jXP02HJ_tkx",
        "outputId": "003ae485-6aad-4166-dbfa-7bfa6efba379"
      },
      "source": [
        "# Create quick lambda functions to find the polarity and subjectivity of each speech\n",
        "from textblob import TextBlob\n",
        "\n",
        "pol = lambda x: TextBlob(x).sentiment.polarity\n",
        "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
        "\n",
        "df['polarity'] = df['Review Text'].apply(pol)\n",
        "df['subjectivity'] = df['Review Text'].apply(sub)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "      <th>words_count</th>\n",
              "      <th>punct_count</th>\n",
              "      <th>stopwords_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love dress sooo pretti happen find store im gl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high hope dress realli want work initi order p...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0.069412</td>\n",
              "      <td>0.388065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.658333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Text  ...  subjectivity\n",
              "0                  absolut wonder silki sexi comfort  ...      0.000000\n",
              "1  love dress sooo pretti happen find store im gl...  ...      0.712500\n",
              "2  high hope dress realli want work initi order p...  ...      0.388065\n",
              "3  love love love jumpsuit fun flirti fabul everi...  ...      0.550000\n",
              "4  shirt flatter due adjust front tie perfect len...  ...      0.658333\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuMsVEkLBbTf"
      },
      "source": [
        "def getSIA(text):\n",
        "  sia=SentimentIntensityAnalyzer()\n",
        "  sentiment=sia.polarity_scores(text)\n",
        "  return sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7pUapuuEBIN",
        "outputId": "d1f02a99-2b9d-4df0-8ec8-e5ed287f6c44"
      },
      "source": [
        "getSIA(\"michel is a good person\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.4404, 'neg': 0.0, 'neu': 0.58, 'pos': 0.42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxHic9LPG6-R"
      },
      "source": [
        "df=df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XboB1-Olgxau",
        "outputId": "1467ef72-1399-4304-ef4d-c4352d20e401"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "      <th>words_count</th>\n",
              "      <th>punct_count</th>\n",
              "      <th>stopwords_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>love dress sooo pretti happen find store im gl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>high hope dress realli want work initi order p...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0.069412</td>\n",
              "      <td>0.388065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.658333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22636</th>\n",
              "      <td>23481</td>\n",
              "      <td>happi snag dress great price easi slip flatter...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22637</th>\n",
              "      <td>23482</td>\n",
              "      <td>remind matern cloth soft stretchi shini materi...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0.146429</td>\n",
              "      <td>0.660714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22638</th>\n",
              "      <td>23483</td>\n",
              "      <td>fit well top see never would work im glad abl ...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22639</th>\n",
              "      <td>23484</td>\n",
              "      <td>bought dress wed summer cute unfortun fit isnt...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22640</th>\n",
              "      <td>23485</td>\n",
              "      <td>dress love platinum feminin fit perfectli easi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22641 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... subjectivity\n",
              "0          0  ...     0.000000\n",
              "1          1  ...     0.712500\n",
              "2          2  ...     0.388065\n",
              "3          3  ...     0.550000\n",
              "4          4  ...     0.658333\n",
              "...      ...  ...          ...\n",
              "22636  23481  ...     0.750000\n",
              "22637  23482  ...     0.660714\n",
              "22638  23483  ...     0.662500\n",
              "22639  23484  ...     0.450000\n",
              "22640  23485  ...     0.500000\n",
              "\n",
              "[22641 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI7Qf4uNJKiZ"
      },
      "source": [
        "df.drop(columns=[\"index\"],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "R2JSp9jQg56R",
        "outputId": "fff02570-9bc4-4230-89c2-51d3dd4b8ddc"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "      <th>words_count</th>\n",
              "      <th>punct_count</th>\n",
              "      <th>stopwords_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love dress sooo pretti happen find store im gl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high hope dress realli want work initi order p...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0.069412</td>\n",
              "      <td>0.388065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.658333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22636</th>\n",
              "      <td>happi snag dress great price easi slip flatter...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22637</th>\n",
              "      <td>remind matern cloth soft stretchi shini materi...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0.146429</td>\n",
              "      <td>0.660714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22638</th>\n",
              "      <td>fit well top see never would work im glad abl ...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22639</th>\n",
              "      <td>bought dress wed summer cute unfortun fit isnt...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22640</th>\n",
              "      <td>dress love platinum feminin fit perfectli easi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22641 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Review Text  ...  subjectivity\n",
              "0                      absolut wonder silki sexi comfort  ...      0.000000\n",
              "1      love dress sooo pretti happen find store im gl...  ...      0.712500\n",
              "2      high hope dress realli want work initi order p...  ...      0.388065\n",
              "3      love love love jumpsuit fun flirti fabul everi...  ...      0.550000\n",
              "4      shirt flatter due adjust front tie perfect len...  ...      0.658333\n",
              "...                                                  ...  ...           ...\n",
              "22636  happi snag dress great price easi slip flatter...  ...      0.750000\n",
              "22637  remind matern cloth soft stretchi shini materi...  ...      0.660714\n",
              "22638  fit well top see never would work im glad abl ...  ...      0.662500\n",
              "22639  bought dress wed summer cute unfortun fit isnt...  ...      0.450000\n",
              "22640  dress love platinum feminin fit perfectli easi...  ...      0.500000\n",
              "\n",
              "[22641 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMwB_pWxDIeZ"
      },
      "source": [
        "\n",
        "\n",
        "compound=[]\n",
        "neg=[]\n",
        "pos=[]\n",
        "neu=[]\n",
        "SIA=0\n",
        "for i in range(0,len(df[\"Review Text\"])):\n",
        "  SIA = getSIA(df[\"Review Text\"][i])\n",
        "  compound.append(SIA['compound'])\n",
        "  neg.append(SIA['neg'])\n",
        "  neu.append(SIA['neu'])\n",
        "  pos.append(SIA['pos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgCg8wSaIOkw"
      },
      "source": [
        "df[\"compound\"]=compound\n",
        "df[\"neg\"]=neg\n",
        "df[\"neu\"]=neu\n",
        "df[\"pos\"]=pos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a_XnwvvIIhe6",
        "outputId": "87cece74-159b-4150-e823-20b1db714673"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>value</th>\n",
              "      <th>words_count</th>\n",
              "      <th>punct_count</th>\n",
              "      <th>stopwords_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>compound</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>4</td>\n",
              "      <td>good</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love dress sooo pretti happen find store im gl...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.9349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.647</td>\n",
              "      <td>0.353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high hope dress realli want work initi order p...</td>\n",
              "      <td>3</td>\n",
              "      <td>bad</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0.069412</td>\n",
              "      <td>0.388065</td>\n",
              "      <td>0.9186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.9753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257</td>\n",
              "      <td>0.743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.8860</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.513</td>\n",
              "      <td>0.487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Text  Rating  ...    neu    pos\n",
              "0                  absolut wonder silki sexi comfort       4  ...  0.615  0.385\n",
              "1  love dress sooo pretti happen find store im gl...       5  ...  0.647  0.353\n",
              "2  high hope dress realli want work initi order p...       3  ...  0.719  0.281\n",
              "3  love love love jumpsuit fun flirti fabul everi...       5  ...  0.257  0.743\n",
              "4  shirt flatter due adjust front tie perfect len...       5  ...  0.513  0.487\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy4UVEWpIq1g"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=2000)\n",
        "X=tfidf.fit_transform(df['Review Text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD7aZQ1pJhCX",
        "outputId": "34a11485-c5b6-4779-d7fc-3240455a58a9"
      },
      "source": [
        "new_features = df[['words_count','punct_count','stopwords_count','polarity'\t,'subjectivity',\t'compound',\t'neg'\t,'neu',\t'pos']].to_numpy()\n",
        "new_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  5.   ,   0.   ,  15.   , ...,   0.   ,   0.615,   0.385],\n",
              "       [ 30.   ,   0.   ,  62.   , ...,   0.   ,   0.647,   0.353],\n",
              "       [ 48.   ,   0.   , 104.   , ...,   0.   ,   0.719,   0.281],\n",
              "       ...,\n",
              "       [ 19.   ,   0.   ,  34.   , ...,   0.   ,   0.509,   0.491],\n",
              "       [ 38.   ,   0.   ,  84.   , ...,   0.108,   0.655,   0.237],\n",
              "       [ 11.   ,   0.   ,  28.   , ...,   0.   ,   0.465,   0.535]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjdJc4hUKhCv"
      },
      "source": [
        "new_x = np.concatenate((X.toarray(),new_features), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ECt2pRTKlvZ",
        "outputId": "cc570cf6-b627-457c-beeb-3d4cf32b021a"
      },
      "source": [
        "new_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22641, 2009)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRxXMb8RK1Wm",
        "outputId": "05207542-c6c0-4025-e98c-4326b8af2ef4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df[['value']])\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIKyFhaaXnmG"
      },
      "source": [
        " from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler().fit(new_x)\n",
        "new_x=scaler.transform(new_x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JP-ZzBOB_7X",
        "outputId": "4d91fce3-f266-4f44-a768-6a53f5bfb994"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
        "\n",
        "# Fit the model to generate the data.\n",
        "oversampled_trainX, oversampled_trainY = sm.fit_sample(new_x, y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5Yn2EwhCaJ5",
        "outputId": "6be74962-5118-4f0e-a97f-b00c94d9ae0f"
      },
      "source": [
        "count1=0\n",
        "count2=0\n",
        "for i in oversampled_trainY:\n",
        "  if i ==1:\n",
        "    count1+=1\n",
        "  else:\n",
        "    count2+=1\n",
        "print(count1)\n",
        "print(count2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17448\n",
            "17448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H55rstg6LAER"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(oversampled_trainX,oversampled_trainY,train_size=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX74gMCZLDzK",
        "outputId": "95163736-19a3-4821-d837-2215cbbf1629"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27916, 2009), (6980, 2009), (27916,), (6980,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPaVUUsjdmR4",
        "outputId": "9f5b13cc-234c-401d-cc9d-004d244aba9d"
      },
      "source": [
        "X_train[0].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kCWhWo4LJfe"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq94gW61LL-D"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=2009))\n",
        "model.add(Dense(1000))\n",
        "model.add(Dense(100))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aqI8UgnLNcu",
        "outputId": "5cbe37c0-2e99-424d-cbb9-fc67f93e5530"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 1000)              2010000   \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               100100    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,110,201\n",
            "Trainable params: 2,110,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SogmWv2cLNm8"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEYW05TsLikq",
        "outputId": "590e6dc6-6896-405d-84e3-8b549aa8aa78"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test),batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "110/110 [==============================] - 8s 65ms/step - loss: 0.6798 - accuracy: 0.7632 - val_loss: 0.4454 - val_accuracy: 0.8470\n",
            "Epoch 2/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3525 - accuracy: 0.8626 - val_loss: 0.4282 - val_accuracy: 0.8643\n",
            "Epoch 3/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3095 - accuracy: 0.8808 - val_loss: 0.4064 - val_accuracy: 0.8693\n",
            "Epoch 4/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2854 - accuracy: 0.8900 - val_loss: 0.4115 - val_accuracy: 0.8106\n",
            "Epoch 5/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2808 - accuracy: 0.8898 - val_loss: 0.3566 - val_accuracy: 0.8744\n",
            "Epoch 6/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2704 - accuracy: 0.8961 - val_loss: 0.3592 - val_accuracy: 0.8716\n",
            "Epoch 7/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2564 - accuracy: 0.9031 - val_loss: 0.3287 - val_accuracy: 0.8779\n",
            "Epoch 8/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2508 - accuracy: 0.9041 - val_loss: 0.3304 - val_accuracy: 0.8745\n",
            "Epoch 9/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2476 - accuracy: 0.9056 - val_loss: 0.3211 - val_accuracy: 0.8774\n",
            "Epoch 10/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2461 - accuracy: 0.9069 - val_loss: 0.3254 - val_accuracy: 0.8792\n",
            "Epoch 11/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2476 - accuracy: 0.9076 - val_loss: 0.3236 - val_accuracy: 0.8785\n",
            "Epoch 12/20\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2455 - accuracy: 0.9084 - val_loss: 0.3103 - val_accuracy: 0.8797\n",
            "Epoch 13/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2477 - accuracy: 0.9059 - val_loss: 0.3266 - val_accuracy: 0.8764\n",
            "Epoch 14/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2504 - accuracy: 0.9052 - val_loss: 0.3259 - val_accuracy: 0.8815\n",
            "Epoch 15/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2370 - accuracy: 0.9140 - val_loss: 0.3265 - val_accuracy: 0.8703\n",
            "Epoch 16/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2388 - accuracy: 0.9104 - val_loss: 0.3331 - val_accuracy: 0.8759\n",
            "Epoch 17/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2430 - accuracy: 0.9068 - val_loss: 0.3263 - val_accuracy: 0.8798\n",
            "Epoch 18/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2400 - accuracy: 0.9102 - val_loss: 0.3212 - val_accuracy: 0.8808\n",
            "Epoch 19/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2405 - accuracy: 0.9078 - val_loss: 0.3118 - val_accuracy: 0.8775\n",
            "Epoch 20/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2396 - accuracy: 0.9109 - val_loss: 0.3325 - val_accuracy: 0.8794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61b482e510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teKhzwMkNsjW"
      },
      "source": [
        "                                          \n",
        "# Apply a second round of cleaning\n",
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "def clean_text(text): \n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    tokenized_text = nltk.tokenize.word_tokenize(text.lower())\n",
        "    alphabetic_text = [w for w in tokenized_text if w.isalpha()]\n",
        "    alphabetic_text\n",
        "    text = [w for w in alphabetic_text if w not in stopwords]\n",
        "    stemmed = [stemmer.stem(w) for w in text]\n",
        "    new_text = ' '.join(stemmed)\n",
        "    return new_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuIAl7BZix5L",
        "outputId": "40af30aa-6f11-4151-8565-0674698070ab"
      },
      "source": [
        "TextBlob(\"hello\").sentiment.subjectivity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APtFCyQJQItB",
        "outputId": "ed7acbb9-8b91-4175-a5a2-a51603667bbf"
      },
      "source": [
        "model.evaluate(X_test,y_test)[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8793696165084839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5T27d4pLj9h"
      },
      "source": [
        "def predict_text():\n",
        "    text = input(\"Enter review: \")\n",
        "    text_features = tfidf.transform([clean_text(text)])\n",
        "    words_count = len(text.split(' '))\n",
        "    punct_count = len([x for x in text if x in (';', ':', ',', '.', '!', '?')])\n",
        "    stopwords_count = len([x for x in text if x in stopwords])\n",
        "    SIA=getSIA(text)\n",
        "    pol = TextBlob(text).sentiment.polarity\n",
        "    sub = TextBlob(text).sentiment.subjectivity\n",
        "    compound=SIA['compound']\n",
        "    neg=SIA['neg']\n",
        "    neu=SIA['neu']\n",
        "    pos=SIA['pos']\n",
        "    new=pd.DataFrame({'words_count':words_count,'punct_count':punct_count,'stopwords_count':stopwords_count,'polarity':pol\t,'subjectivity':sub,\t'compound':compound,\t'neg':neg\t,'neu':neu,\t'pos':pos}, index=[0])\n",
        "    new_features1 = new[['words_count','punct_count','stopwords_count','polarity'\t,'subjectivity',\t'compound',\t'neg'\t,'neu',\t'pos']].to_numpy()\n",
        "    new_features2 = np.concatenate((text_features.toarray(),new_features1), axis=1)\n",
        "    new_features2=scaler.transform(new_features2)\n",
        "    prediction = model.predict(new_features2)\n",
        "    prediction_rounded= round(prediction[0][0])\n",
        "    if prediction <=0.4 :\n",
        "      return \"with a {:.2f}% confidence the review is {}\".format((1-prediction[0][0])*100,encoder.inverse_transform([prediction_rounded])[0])\n",
        "    if prediction >=0.6 :\n",
        "      return \"with a {:.2f}% confidence the review is {}\".format((prediction[0][0])*100,encoder.inverse_transform([prediction_rounded])[0])\n",
        "    else:\n",
        "      return \"the can't significantly predict if it's good or bad\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Atid9-dVoXx7",
        "outputId": "7733e2af-1780-4c33-c4ab-3947a0da85e2"
      },
      "source": [
        "df.iloc[22639][\"Review Text\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bought dress wed summer cute unfortun fit isnt perfect medium fit waist perfectli way long big bust shoulder want spend money could get tailor felt like might worth side note dress deliv nordstrom tag found much cheaper look'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLLO7woTN8gU",
        "outputId": "d0395f2b-ea08-4c94-d0a7-3f07eead26a9"
      },
      "source": [
        "round(0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pvrr81FRLkkW",
        "outputId": "cf5cfd67-fcb6-4ec6-be01-996a6657fe28"
      },
      "source": [
        "predict_text()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter review: bought dress wed summer cute unfortun fit isnt perfect medium fit waist perfectli way long big bust shoulder want spend money could get tailor felt like might worth side note dress deliv nordstrom tag found much cheaper look\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'with a 94.27% confidence the review is bad'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQouhyMHqUlL"
      },
      "source": [
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPnV50oHuEqP"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htHz2o64uJSj",
        "outputId": "bbae2a66-f87d-446c-cb2b-25032243a308"
      },
      "source": [
        "model_MLP=MLPClassifier(activation='logistic',solver='adam',max_iter=100)\n",
        "model_MLP.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2-O0_GCuPTc",
        "outputId": "9743eef5-4e5b-4179-99df-795c6c9c98fc"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "test_predictions=model_MLP.predict(X_test)\n",
        "test_accuracy = accuracy_score(test_predictions,y_test)\n",
        "print (\"validation Accuracy : {0:.4%}\".format(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation Accuracy : 85.8688%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hvNuyTjSz55c",
        "outputId": "82d80c5a-712e-4f43-ca84-846ae91d214a"
      },
      "source": [
        "clf = GridSearchCV(model_MLP, {\n",
        "            'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
        "            'solver' : ['lbfgs', 'sgd', 'adam']\n",
        "                               }, cv=5, return_train_score=False)\n",
        "clf.fit(X_test, y_test)\n",
        "dfcv = pd.DataFrame(clf.cv_results_)[['param_activation','param_solver','mean_test_score']].sort_values('mean_test_score')\n",
        "display(dfcv)\n",
        "print(f\"best params: {clf.best_params_}\")\n",
        "print(f\"best score: {clf.best_score_}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_activation</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>relu</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.324945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>identity</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.506182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.635710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>identity</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.684275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tanh</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.749615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>logistic</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.756684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>logistic</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.769927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tanh</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.769927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tanh</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.818059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>identity</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.820487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.823581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>logistic</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.837490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   param_activation param_solver  mean_test_score\n",
              "9              relu        lbfgs         0.324945\n",
              "0          identity        lbfgs         0.506182\n",
              "10             relu          sgd         0.635710\n",
              "1          identity          sgd         0.684275\n",
              "6              tanh        lbfgs         0.749615\n",
              "3          logistic        lbfgs         0.756684\n",
              "4          logistic          sgd         0.769927\n",
              "7              tanh          sgd         0.769927\n",
              "8              tanh         adam         0.818059\n",
              "2          identity         adam         0.820487\n",
              "11             relu         adam         0.823581\n",
              "5          logistic         adam         0.837490"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best params: {'activation': 'logistic', 'solver': 'adam'}\n",
            "best score: 0.8374900296366763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNqOa81Jw0_0"
      },
      "source": [
        "def predict_text_MLP():\n",
        "    text = input(\"Enter review: \")\n",
        "    text_features = tfidf.transform([clean_text(text)])\n",
        "    words_count = len(text.split(' '))\n",
        "    punct_count = len([x for x in text if x in (';', ':', ',', '.', '!', '?')])\n",
        "    stopwords_count = len([x for x in text if x in stopwords])\n",
        "    SIA=getSIA(text)\n",
        "    pol = TextBlob(text).sentiment.polarity\n",
        "    sub = TextBlob(text).sentiment.subjectivity\n",
        "    compound=SIA['compound']\n",
        "    neg=SIA['neg']\n",
        "    neu=SIA['neu']\n",
        "    pos=SIA['pos']\n",
        "    new=pd.DataFrame({'words_count':words_count,'punct_count':punct_count,'stopwords_count':stopwords_count,'polarity':pol\t,'subjectivity':sub,\t'compound':compound,\t'neg':neg\t,'neu':neu,\t'pos':pos}, index=[0])\n",
        "    new_features1 = new[['words_count','punct_count','stopwords_count','polarity'\t,'subjectivity',\t'compound',\t'neg'\t,'neu',\t'pos']].to_numpy()\n",
        "    new_features2 = np.concatenate((text_features.toarray(),new_features1), axis=1)\n",
        "    prediction = model_MLP.predict(new_features2)\n",
        "    return encoder.inverse_transform(prediction)[0][0]\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "B5THn1W0yCBS",
        "outputId": "e9a13433-97d7-4925-9b87-874e93e480de"
      },
      "source": [
        "predict_text_MLP()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter review: hihi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'good'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_VsIqUxgNUC",
        "outputId": "a53bc686-9f9b-4961-b3df-ae28b43e34d5"
      },
      "source": [
        "\n",
        "\n",
        "model = RandomForestClassifier(criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57UEcf5uM6C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D3Pq5FouOeg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYvFuXI9rgNI",
        "outputId": "0f977c44-b723-48ef-cb59-38b2890cb0e9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "test_predictions=model.predict(X_test)\n",
        "test_accuracy = accuracy_score(test_predictions,y_test)\n",
        "print (\"validation Accuracy : {0:.4%}\".format(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation Accuracy : 82.9543%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF7IJ0uovYTq"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BjntkOutOEZ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCgV9btZxdAu"
      },
      "source": [
        "# # Keras\n",
        "# from keras.layers import Dense\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Activation\n",
        "# from keras.layers import Embedding, Flatten\n",
        "# from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "# from keras.layers import LSTM\n",
        "# from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "# from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcbWxZIwF2lq"
      },
      "source": [
        "# def build_model(vocab_size, dim, embedding_matrix, max_length):\n",
        "#     model = Sequential()\n",
        "#     model.add(Embedding(vocab_size + 1, dim, weights=[embedding_matrix], input_length=max_length))\n",
        "#     model.add(Dropout(0.4))\n",
        "#     model.add(LSTM(128))\n",
        "#     model.add(Dense(64))\n",
        "#     model.add(Dropout(0.5))\n",
        "#     model.add(Activation('relu'))\n",
        "#     model.add(Dense(2))\n",
        "#     model.add(Activation('sigmoid'))\n",
        "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENOzA8d60CRi"
      },
      "source": [
        "# model = build_model(vocab_size, dim, embedding_matrix, max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mpfyQIh1ABq"
      },
      "source": [
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001)\n",
        "# model.fit(X_train, y_train, batch_size=32, epochs=8, validation_split=0.1, shuffle=True, callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbzdMeB91SGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c2fdf3-ff3c-4f44-8faf-328712b35091"
      },
      "source": [
        "neg_words=[\"sad\",\"anxious\",\"down\", \"stressed\" , \"upset\",\"pain\",\"crazy\",\"fault\",\"can't\",\"cannot\",\"loneliness\",\"sadness\",\"rage\"]\n",
        "b=input(\"write aBOUT YOUR SELF:\")\n",
        "b=b.split()\n",
        "w=[]\n",
        "binary=0\n",
        "for i in b:\n",
        "    if i.lower() in neg_words:\n",
        "        w.append(i)\n",
        "        binary=1\n",
        "print(w)\n",
        "print (binary)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "write aBOUT YOUR SELF:i am sad and stressed\n",
            "['sad', 'stressed']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}